{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Based on: [https://github.com/MicrosoftLearning/mslearn-azure-ml/blob/main/Labs/07/Track%20model%20training%20with%20MLflow.ipynb]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1757168197772
        }
      },
      "outputs": [],
      "source": [
        "# Import the required libraries\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# The workspace information from the previous experiment has been pre-filled for you.\n",
        "subscription_id = \"your-subscription-id\"\n",
        "resource_group = \"ml-corp-test-rg\"\n",
        "workspace_name = \"ml-corp-test-ws\"\n",
        "\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client = MLClient(credential, subscription_id, resource_group, workspace_name)\n",
        "workspace = ml_client.workspaces.get(name=ml_client.workspace_name)\n",
        "print(ml_client.workspace_name, workspace.resource_group, workspace.location, ml_client.connections._subscription_id, sep = '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756892129233
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"Reading data...\")\n",
        "df = pd.read_csv('./diabetes-data/diabetes.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Create data frame, X and Y data for Train and split Data for Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756892239815
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"splitting data and train\")\n",
        "\n",
        "X, y = df[\n",
        "    ['Pregnancies',\n",
        "    'PlasmaGlucose',\n",
        "    'DiastolicBloodPressure',\n",
        "    'TricepsThickness',\n",
        "    'SerumInsulin',\n",
        "    'BMI',\n",
        "    'DiabetesPedigree',\n",
        "    'Age']].values, df['Diabetic'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756892154509
        }
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "experiment_name = \"mlflow-experiment-diabetes\"\n",
        "mlflow.set_experiment(experiment_name) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756806055511
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "with mlflow.start_run():\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "    model = LogisticRegression(C=1/0.1, solver=\"liblinear\").fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Custom Model Tracking part, without autolog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1756806132956
        }
      },
      "outputs": [],
      "source": [
        "mlflow.sklearn.autolog(disable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756808478925
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "with mlflow.start_run():\n",
        "    model = LogisticRegression(C=1/0.1, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "\n",
        "    mlflow.log_param(\"regularization_rate\", 0.1)\n",
        "    mlflow.log_metric(\"Accuracy\", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756808926616
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "with mlflow.start_run():\n",
        "    model = LogisticRegression(C=1/0.01, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "\n",
        "    mlflow.log_param(\"regularization_rate\", 0.01)\n",
        "    mlflow.log_metric(\"Accuracy\", acc)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756809723586
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "\n",
        "with mlflow.start_run():\n",
        "    model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "\n",
        "    mlflow.log_param(\"estimator\", \"DecisionTreeClassifier\")\n",
        "    mlflow.log_metric(\"Accuracy\", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756893110621
        }
      },
      "outputs": [],
      "source": [
        " pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Custom Part: Uses XGBClassifier alghorithm to train Classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756893513936
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "with mlflow.start_run():\n",
        "    # model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "    model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\").fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "\n",
        "    # plot ROC curve\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\")\n",
        "\n",
        "    mlflow.log_param(\"estimator\", \"DecisionTreeClassifier\")\n",
        "    mlflow.log_metric(\"Accuracy\", acc)\n",
        "    mlflow.log_artifact(\"ROC-Curve.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Custom Training Script that saves and shows predictions right a way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756892538284
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import os\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# --- assume we already have:\n",
        "# model = LogisticRegression(...).fit(X_train, y_train)\n",
        "\n",
        "with mlflow.start_run():\n",
        "    mlflow.sklearn.autolog()\n",
        "    model = LogisticRegression(C=1/0.1, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    # ---------- PREDICTIONS ----------\n",
        "    # choose the dataset you want predictions for (X_test/y_test or X_train/y_train)\n",
        "    X_eval = X_test      # change if you want predictions for train set\n",
        "    y_true = y_test\n",
        "\n",
        "    # Convert X_eval to DataFrame (keep feature names if available)\n",
        "    if isinstance(X_eval, pd.DataFrame):\n",
        "        df_X = X_eval.copy()\n",
        "    else:\n",
        "        # if X_train was a DataFrame, reuse its columns; otherwise create numeric names\n",
        "        if isinstance(X_train, pd.DataFrame):\n",
        "            cols = X_train.columns\n",
        "        else:\n",
        "            cols = [f\"feature_{i}\" for i in range(np.shape(X_eval)[1])]\n",
        "        df_X = pd.DataFrame(X_eval, columns=cols)\n",
        "\n",
        "    # Predictions and probabilities\n",
        "    y_pred = model.predict(X_eval)\n",
        "    # predict_proba might not exist for some classifiers â€” handle carefully\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        probs = model.predict_proba(X_eval)\n",
        "        # for binary, take probability of class 1 as a convenience column:\n",
        "        if probs.shape[1] == 2:\n",
        "            prob_pos = probs[:, 1]\n",
        "            df_probs = pd.DataFrame({\"prob_neg\": probs[:, 0], \"prob_pos\": probs[:, 1]})\n",
        "        else:\n",
        "            # multiclass: create prob_class_<label> columns\n",
        "            class_labels = model.classes_\n",
        "            df_probs = pd.DataFrame(probs, columns=[f\"prob_class_{c}\" for c in class_labels])\n",
        "    else:\n",
        "        df_probs = pd.DataFrame()  # empty if not available\n",
        "\n",
        "    # Build result table\n",
        "    df_results = df_X.reset_index(drop=True).copy()\n",
        "    df_results[\"y_true\"] = np.array(y_true).reshape(-1)\n",
        "    df_results[\"y_pred\"] = np.array(y_pred).reshape(-1)\n",
        "    if not df_probs.empty:\n",
        "        df_results = pd.concat([df_results, df_probs.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    # Optional: add prediction score (decision_function) if available\n",
        "    if hasattr(model, \"decision_function\"):\n",
        "        try:\n",
        "            df_results[\"score\"] = model.decision_function(X_eval)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # ---------- SAVE & LOG ----------\n",
        "    out_dir = \"predictions\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    csv_path = os.path.join(out_dir, \"predictions_table.csv\")\n",
        "    df_results.to_csv(csv_path, index=False)\n",
        "\n",
        "    # Try mlflow.log_table if available (MLflow >= 2.0). Otherwise log CSV as artifact.\n",
        "    try:\n",
        "        if hasattr(mlflow, \"log_table\"):\n",
        "            mlflow.log_table(df_results, artifact_file=\"predictions_table\")  # stores table in run\n",
        "        else:\n",
        "            raise AttributeError\n",
        "    except Exception:\n",
        "        mlflow.log_artifact(csv_path, artifact_path=\"predictions\")\n",
        "\n",
        "    # ---------- QUICK METRICS (optional) ----------\n",
        "    from sklearn.metrics import classification_report, confusion_matrix\n",
        "    report = classification_report(y_true, y_pred, output_dict=True)\n",
        "    # Log a simple numeric metric example: accuracy\n",
        "    accuracy = report.get(\"accuracy\")\n",
        "    if accuracy is not None:\n",
        "        mlflow.log_metric(\"accuracy\", float(accuracy))\n",
        "\n",
        "    # show a preview (useful in notebooks)\n",
        "    print(df_results.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1757168359635
        }
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "\n",
        "print(\"experiments\")\n",
        "experiments = mlflow.search_experiments(max_results=10)\n",
        "for exp in experiments:\n",
        "    print(exp.name)\n",
        "\n",
        "print(\"search runs\")\n",
        "mlflow.search_runs(exp.experiment_id)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
