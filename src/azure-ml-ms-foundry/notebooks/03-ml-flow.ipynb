{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Based on Labs: \n",
        "    \n",
        "1. https://github.com/MicrosoftLearning/mslearn-azure-ml/blob/main/Labs/08/Run%20script%20as%20a%20command%20job.ipynb \n",
        "\n",
        "2. https://github.com/MicrosoftLearning/mslearn-azure-ml/blob/main/Labs/08/Use%20MLflow%20to%20track%20jobs.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756980649311
        }
      },
      "outputs": [],
      "source": [
        "# Import the required libraries\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# The workspace information from the previous experiment has been pre-filled for you.\n",
        "subscription_id = \"7dae9e0f-de34-4921-91be-67945119f760\"\n",
        "resource_group = \"rg-corp-data-ai-platform-001\"\n",
        "workspace_name = \"ml-workspace-corp-test-swn-001\"\n",
        "\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client = MLClient(credential, subscription_id, resource_group, workspace_name)\n",
        "workspace = ml_client.workspaces.get(name=ml_client.workspace_name)\n",
        "print(ml_client.workspace_name, workspace.resource_group, workspace.location, ml_client.connections._subscription_id, sep = '\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1757167528115
        }
      },
      "outputs": [],
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile train-model-mlflow.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # evaluate model\n",
        "    eval_model(model, X_test, y_test)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
        "    print(\"Training model...\")\n",
        "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "    mlflow.log_metric(\"Accuracy\", acc)\n",
        "\n",
        "    # calculate AUC\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "    print('AUC: ' + str(auc))\n",
        "    mlflow.log_metric(\"AUC\", auc)\n",
        "\n",
        "    # plot ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\")\n",
        "    mlflow.log_artifact(\"ROC-Curve.png\")    \n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
        "                        type=float, default=0.01)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Train Model MLFlow Extended Script. With Updated/Fixed Data Retreival logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile train-model-mlflow-v2.py\n",
        "\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # evaluate model\n",
        "    eval_model(model, X_test, y_test)\n",
        "\n",
        "# function that reads the data\n",
        "# def get_data(path):\n",
        "#     print(\"Reading data...\")\n",
        "#     df = pd.read_csv(path)\n",
        "    \n",
        "#     return df\n",
        "\n",
        "def get_data(path):\n",
        "    import os, glob, tempfile, shutil, csv\n",
        "    from pathlib import Path\n",
        "\n",
        "    p = Path(path)\n",
        "    if p.is_dir():\n",
        "        candidates = sorted(p.glob(\"*.csv\"))\n",
        "        if not candidates:\n",
        "            raise FileNotFoundError(f\"No CSV files in: {p}\")\n",
        "        p = candidates[0]\n",
        "\n",
        "    # copy to local temp to avoid mount read(nbytes) issues\n",
        "    fd, tmp = tempfile.mkstemp(suffix=p.suffix or \".csv\"); os.close(fd)\n",
        "    shutil.copyfile(str(p), tmp)\n",
        "\n",
        "    # detect delimiter (fallback to comma)\n",
        "    try:\n",
        "        with open(tmp, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            sample = f.read(20000)\n",
        "        sep = csv.Sniffer().sniff(sample, delimiters=[\",\",\";\",\"\\t\",\"|\"]).delimiter\n",
        "    except Exception:\n",
        "        sep = \",\"\n",
        "\n",
        "    # robust read with python engine\n",
        "    try:\n",
        "        df = pd.read_csv(tmp, engine=\"python\", sep=sep)\n",
        "    except UnicodeDecodeError:\n",
        "        df = pd.read_csv(tmp, engine=\"python\", sep=sep, encoding=\"latin-1\")\n",
        "\n",
        "    print(f\"Preparing {len(df)} rows of data\")\n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
        "    print(\"Training model...\")\n",
        "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    mlflow.sklearn.save_model(model, args.model_output)\n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "    mlflow.log_metric(\"Accuracy\", acc)\n",
        "\n",
        "    # calculate AUC\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "    print('AUC: ' + str(auc))\n",
        "    mlflow.log_metric(\"AUC\", auc)\n",
        "\n",
        "    # plot ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\")\n",
        "    mlflow.log_artifact(\"ROC-Curve.png\")    \n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
        "                        type=float, default=0.01)\n",
        "    parser.add_argument(\"--model_output\", dest='model_output',\n",
        "                        type=str)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1756982094006
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import command \n",
        "\n",
        "job = command(\n",
        "    code=\"./\",\n",
        "    command=\"python train-model-mlflow.py --training_data diabetes-data/diabetes.csv\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"ml-compute-ntb\",\n",
        "    display_name=\"diabetes-train-mlflow\",\n",
        "    experiment_name=\"diabetes-training\", \n",
        "    tags={\"model_type\": \"LogisticRegression\"}\n",
        "    )\n",
        "\n",
        "ml_client.create_or_update(job)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
